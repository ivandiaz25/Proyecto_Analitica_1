# -*- coding: utf-8 -*-
"""Scritp_final_proyecto .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ejp4AfPo0UYdCDqJfTtwF0ofBhU_7d4Q

#Guía de trabajo Módulo 2 – Aprendizaje Supervisado

 **INTEGRANTES**:

*   Cesar Iván Ávila Díaz
*   Marcelo Lemus
* María Gabriel Pérez
* Verónica Andrea Morales González


**Caso de estudio**

La agencia de marketing Sterling Cooper Advertising tiene en su planta de empleados alrededor de
4.000 personas directamente contratadas. Sin embargo, el departamento de recursos humanos ha
reportado cifras preocupantes a la dirección de la agencia, indicando que cada año, alrededor del
15% de sus empleados abandonan la empresa y necesitan ser reemplazados, en la mayoría de casos,
con muy poco tiempo para el proceso de selección y contratación. La dirección cree que este nivel
de bajas (empleados que se marchan, ya sea por decisión propia o porque son despedidos) es
perjudicial para la empresa, por las siguientes razones:

● Los proyectos de los antiguos empleados se retrasan, lo que dificulta el cumplimiento de los plazos, con la consiguiente pérdida de reputación entre sus clientes y socios.

● El departamento de recursos humanos requiere mucha inversión por los niveles de rotación,así que la mayoría de su personal está dedicado a tareas de reclutamiento de nuevo talento, haciendo más lento el proceso de desarrollo de otras áreas dentro del departamento dedicadas por ejemplo a la formación o bienestar de sus empleados.

● En la mayoría de los casos, hay que formar a los nuevos empleados para el puesto y/o darles
tiempo para que se adapten a la cultura de la agencia.


Por ello, la dirección ha contratado a su equipo de consultores para saber en qué factores deben centrarse para frenar el abandono de empleados. En otras palabras, quieren predecir a tiempo si sus empleados van a abandonar su empleo para tomar acciones preventivas que les permita retener a la mayoría de los empleados en riesgo. También quieren saber cuál de estas variables es la más importante y debe abordarse de inmediato.

# **a. Diseño de solución propuesta**

El objetivo es desarrollar un modelo predictivo que identifique a tiempo a los empleados en riesgo de abandonar la empresa. Esto permitirá tomar acciones preventivas para retener a la mayoría de los empleados en riesgo. La solución propuesta debería incluir un sistema de alerta temprana y recomendaciones personalizadas para retener a los empleados.
"""

# Commented out IPython magic to ensure Python compatibility.
#Preparamos complementos, librerías y bases disponibles
import warnings

warnings.filterwarnings("ignore")

!pip install pandas numpy sweetviz seaborn matplotlib scikit-learn

#Instalación de complemento
!pip install sweetviz

#importar librerias
import pandas as pd
import numpy as np
import sweetviz as sv
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import ShuffleSplit
from sklearn import datasets
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay


# %matplotlib inline

# Lectura de los datos
#df_auto = pd.read_csv('data/auto-mpg.csv')
dfemployee_survey_data= pd.read_csv("https://raw.githubusercontent.com/ivandiaz25/Proyecto_Analitica_1/master/Datasets/employee_survey_data.csv", na_values='?')
dfgeneral_data = pd.read_csv("https://raw.githubusercontent.com/ivandiaz25/Proyecto_Analitica_1/master/Datasets/general_data.csv", na_values='?')
dfmanager_survey_data = pd.read_csv("https://raw.githubusercontent.com/ivandiaz25/Proyecto_Analitica_1/master/Datasets/manager_survey_data.csv", na_values='?')
dftime_work = pd.read_csv("https://raw.githubusercontent.com/ivandiaz25/Proyecto_Analitica_1/master/Datasets/time_work.csv", na_values='?', sep = ';')

"""# **b. Limpieza y transformación de los datos**

Antes de realizar cualquier análisis, los datos deben ser limpiados y transformados. Esto implica tratar valores faltantes, eliminar duplicados, convertir datos categóricos en numéricos si es necesario, y realizar otras tareas de limpieza de datos
"""

#Un primer vistazo para verificar que se hayan cargado las tablas correctamente
dfgeneral_data.head()

#Visualizamos las primeras líneas de los archivos
#Para empleados
dfemployee_survey_data.head()

#Para gerente
dfmanager_survey_data.head()

#Para tiempo de trabajo
dftime_work.head()

#Procedemos a unir las tablas para que sea mas fácil trabajarlas
dftotal=dfgeneral_data.merge(dfemployee_survey_data, on="EmployeeID", how="left")

dftotal2=dftotal.merge(dfmanager_survey_data, on="EmployeeID", how="left")

dftotal3=dftotal2.merge(dftime_work, on="EmployeeID", how="left")

# Tenemos finalmente un solo dataframe combinado con todas las tablas a partir de la columna ID
dfdata=dftotal3.copy()
dfdata.head()

# Ahora realizaremos una revisión inicial de datos para obsevar cómo se encuentra nuestro dataframe
dfdata.shape

# Verificamos lista de variables o etiquetas de las columnas presentes en el DataFrame.
dfdata.columns

#Verificamos la información sobre las columnas y su tipo de datos
dfdata.info()

# Verificamos si hay columnas con datos nulos en el conjunto de datos.
dfdata.isnull().sum()

# como en esta variables hay nulos, analizaremos el número de valores de cada uno.
dfdata['NumCompaniesWorked'].value_counts()

dfdata['TotalWorkingYears'].value_counts()

# para nuestro analisis es mas facil observarlos de mayor a menor, asi que vamos a organizarlos con un pequeño data frame
dfdatay = dfdata.loc[:, ['EmployeeID','TotalWorkingYears']]
dfdatay

ddatay2 = dfdatay.sort_values(by='TotalWorkingYears', ascending=False)
ddatay2

#Una vez observado lo que contiene cada variable procederemos primero a tratar los nulos.
# primero analizaremos el porcentaje de nulos que presenta nuestra base de datos
round(dfdata.isnull().sum().sum()/dfdata.size, 4)*100

#Como observamos el porcentaje de nulos es mucho menor al 0.1% del total de datos, por lo que no son tan significativos, entonces aprovecharemos
#que se encuentran en varibales con respuestas numericas para aproximarlas al promedio, asi:
median_NumCompaniesWorked=round(dfdata['NumCompaniesWorked'].median())
print(median_NumCompaniesWorked)
dfdata['NumCompaniesWorked']=dfdata['NumCompaniesWorked'].fillna(median_NumCompaniesWorked)
print(dfdata['NumCompaniesWorked'].isnull().sum())
print(dfdata['NumCompaniesWorked'].unique())

mode_EnvironmentSatisfaction = dfdata['EnvironmentSatisfaction'].mode()
print(mode_EnvironmentSatisfaction)
dfdata['EnvironmentSatisfaction'].fillna(mode_EnvironmentSatisfaction[0], inplace=True)
print(dfdata['EnvironmentSatisfaction'].isnull().sum())
print(dfdata['EnvironmentSatisfaction'].unique())

median_TotalWorkingYears=round(dfdata['TotalWorkingYears'].median())
print(median_TotalWorkingYears)
dfdata['TotalWorkingYears']=dfdata['TotalWorkingYears'].fillna(median_NumCompaniesWorked)
print(dfdata['TotalWorkingYears'].isnull().sum())
print(dfdata['TotalWorkingYears'].unique())

mode_JobSatisfaction = dfdata['JobSatisfaction'].mode()
print(mode_JobSatisfaction)
dfdata['JobSatisfaction'].fillna(mode_JobSatisfaction[0], inplace=True)
print(dfdata['JobSatisfaction'].isnull().sum())
print(dfdata['JobSatisfaction'].unique())

mode_WorkLifeBalance = dfdata['WorkLifeBalance'].mode()
print(mode_WorkLifeBalance)
dfdata['WorkLifeBalance'].fillna(mode_WorkLifeBalance[0], inplace=True)
print(dfdata['WorkLifeBalance'].isnull().sum())
print(dfdata['WorkLifeBalance'].unique())

dfdata['mean_time'] = dfdata['mean_time'].str.replace(',', '.')

dfdata['mean_time'] = pd.to_numeric(dfdata['mean_time'], errors='coerce')
print(dfdata['mean_time'])

mean_mean_time=(dfdata['mean_time'].mean())
print(mean_mean_time)
dfdata['mean_time']=dfdata['mean_time'].fillna(mean_mean_time)
print(dfdata['mean_time'].isnull().sum())
print(dfdata['mean_time'].unique())

# Como podemos observar ahora ya fueron tratados todos los nulos, por lo tanto podemos proceder a realizar el análisis exploratorio para entender mejor
# el comportamiento de nuestras variables
dfdata.isnull().sum()

df_datafinal = dfdata.loc[:,['Age','DistanceFromHome', 'MonthlyIncome', 'NumCompaniesWorked','PercentSalaryHike','TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'mean_time','BusinessTravel', 'Department', 'EducationField', 'Gender','JobRole', 'MaritalStatus', 'Education','JobLevel', 'StockOptionLevel',  'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'JobInvolvement', 'PerformanceRating', 'Attrition']]

df_datafinal.shape

df_datafinal.describe()

#ahora estudiaremos mejor el comportamiento de las variables para observar la aproximación de nuestro analisiS exploratorio
df_datafinal[['StockOptionLevel', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']]= df_datafinal[['StockOptionLevel', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']].astype(str)

df_datafinal[['Age', 'DistanceFromHome', 'MonthlyIncome', 'NumCompaniesWorked',
       'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear',
       'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager',
       'mean_time']] = df_datafinal[['Age', 'DistanceFromHome', 'MonthlyIncome', 'NumCompaniesWorked',
       'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear',
       'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager',
       'mean_time']].astype(float)

df_datafinal.info()

df2_dummys = pd.get_dummies(df_datafinal.iloc[:,:-1])
df2_dummys.head()

df2_dummys.columns

# imprimir los valores únicos de cada columna.
for columna in dfdata.columns[:]:
  print('\n {}'.format(columna))
  print(dfdata[columna].unique())

"""# **c. Análisis exploratorio de los datos**

Explorar los datos para comprender las características de los empleados que abandonan la empresa. Esto podría incluir análisis de estadísticas descriptivas, visualización de datos y la identificación de patrones preliminares.
"""

#ahora haremos una exploración rapida de las variables
rgd = sv.analyze(df_datafinal)
rgd.show_notebook()

"""La mayoría de los empleados de la empresa se encuentra con salarios entre los 25.000 y los 50.000 dólares, y en menor proporción algunos empleados ganan más de 150.000 dólares.

En cuanto al nivel de satisfacción laboral; la mayoría está ubicada entre los puntajes 3 y 4. En el nivel de implicación en el trabajo, la gran mayoría de empleados se ubica en puntaje 3

En el entorno de trabajo, el nivel de satisfacción predomina entre los puntajes 3 y 4, sin embargo, hay una cantidad también representativa en los menores puntajes. En cuanto a la valoración del rendimiento del último año, se ubica en su mayoría en puntaje 3 y una pequeña proporción en puntaje 4. La mayoría de empleados son de género masculino.

Se observa que la gran mayoría de empleados pertenecen al departamento de investigación y desarrollo, en segundo lugar con una notable diferencia, está el departamento de ventas y finalmente el departamento de recursos humanos es quien tiene la menor cantidad de empleados.

En cuanto al nivel de educación, en una escala de 1 a 5, la mayoría de empleados está con una educación de nivel medio representado en 3.0, otra cantidad representativa tiene nivel 4 de estudio y una pequeña proporción tiene nivel 5. Por otro lado, una cantidad considerable de empleados, tienen bajos niveles educativos.

Entre los campos de estudio de los empleados, la mayoría está formada en cincias para la vida, y en segundo lugar está el campo de la medicina. En otras bajas proporciones, está mercadeo, titulos técnicos y recursos humanos y otra clasificación para diferentes campos.

**Ahora comparemos algunas variables con la variable retiros que es el objetivo**
"""

# Personas de que edad se retiran mas
pd.crosstab(index=df_datafinal['Age'],
            columns=df_datafinal["Attrition"]).plot(kind='bar', figsize=(25,5),colormap='summer')
#Los colaboradores que mas se retiran estan entre los 29 y los 31 años

# Que genero es el que se esta retirando mas y el de los colaboradores
pd.crosstab(index=df_datafinal['Gender'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(10,5),colormap='summer')
#Los hombres son el genero que mas se ha retirado

# Rol en la empresa de los colaboradoresy retirados
pd.crosstab(index=df_datafinal['JobRole'],
            columns=df_datafinal['Attrition']).plot(kind='barh', figsize=(20,10), colormap='summer')
#El rol que mas se retira es de sales executive y Research scientist

# Profesion de los colaboradores y retirados
pd.crosstab(index=df_datafinal['EducationField'],
            columns=df_datafinal['Attrition']).plot(kind='barh', figsize=(20,10), colormap='summer')
#La profesion que mas se retira en "la empresa" es life science

#Satisfacción de los colaboradores y retirados con el ambiente de trabajo
pd.crosstab(index=df_datafinal['EnvironmentSatisfaction'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(25,10), colormap='summer')
#Los colaboradores que mas se han retirado son los que califican como baja su satisfaccion con el ambiente laboral

#Balance de vida de colaboradores y retirados
pd.crosstab(index=df_datafinal['WorkLifeBalance'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(25,10), colormap='summer')
#Los empleados que dicen tener un balance entre su vida laboral y el trabajo entre bueno y excelente son los que mas desercicion han ten

#Los colaboradores y retirados y sus viajes por negocios
pd.crosstab(index=df_datafinal['BusinessTravel'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(27,10), colormap='summer')
#Los colaboradores tanto los activos como los que renunciaron rara vez viajan, y la población de los que rara vez viajan son los que tie

# Años que han pasado desde la ultima promoción en general
pd.crosstab(index=df_datafinal['YearsSinceLastPromotion'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(20,7), colormap='summer')
#Los que mas retiran son los que nuncca han tenido una promocion seguido de los que promovieron hace un año.

# Años bajo el mando del gerente actual en general
pd.crosstab(index=df_datafinal['YearsWithCurrManager'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(20,7), colormap='summer')
# La mayoria de los que se retiran no han pasado ni un año con el gerente actual, seguido de los que llevanban 2 años bajo su mando y luego los q

#Grafico de correlación

plt.figure (figsize=(20, 10), dpi=80);
sns.heatmap(df_datafinal.corr(), annot = True,cmap='summer');
#Hay correlación fuerte positiva en las variables percentSalaryHike, PerformanceRating, YearsAtCompany,

#Retiros segun los Años Trabajados
pd.crosstab(index=df_datafinal['TotalWorkingYears'],
            columns=df_datafinal['Attrition']).plot(kind='bar', figsize=(20,7), colormap='summer')
#Los empelados que mas renuncian son los que llevan un año trabajado

#Promedio de salario mensual de empleados que renuncian
df_datafinal.groupby(["Attrition"])[["MonthlyIncome"]].mean().round(2).reset_index().rename(columns={'MonthlyIncome':'Salario Promedio'})
#el salario promedio de las personas que renuncian es menor que las que no por casi 4000 de diferencia

#Promedio de horas trabajadas de empleados que renuncian
df_datafinal.groupby(["Attrition"])[["mean_time"]].mean().round(2).reset_index()
#Los empleados que renuncian trabajan en promedio casi una hora mas diaria que los que no lo hacen.

df_datafinal['Attrition'].value_counts().plot(kind='bar')

"""# **d. Preparación de los datos**

Preparar los datos para el modelado, dividiéndolos en conjuntos de entrenamiento y prueba. Además, realizar la codificación de variables categóricas y normalización de datos si es necesario.

**Separaración de variables y características**
"""

X = df2_dummys
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

print(y[0:5])

"""**Train/Test split**"""

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

"""# **e. Selección de variables**

Identificar las variables más relevantes para la predicción de abandono de empleados.

###Variance Threshold
Elimina todas las características cuya varianza no alcanza algún umbral.
De forma predeterminada, elimina todas las características de varianza cero, es decir, las características que tienen el mismo valor en todas las muestras.
"""

X = df2_dummys

#Variance Threshold
from sklearn.feature_selection import VarianceThreshold

#Función de filtro de caracteristicas
def variance_threshold(x,th):
    var_thres=VarianceThreshold(threshold=th)
    var_thres.fit(x)
    new_cols = var_thres.get_support()
    return new_cols

# Obtener columnas seleccionadas
X_new = variance_threshold(X, 0.5)
# Nuevo dataframe
df_new = df2_dummys.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###RFE
El objetivo de la eliminación recursiva de características (RFE) es seleccionar características considerando recursivamente conjuntos de características cada vez más pequeños.
"""

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

from sklearn.feature_selection import RFE

# Función recursiva de selección de características
def recursive_feature_selection(X,y,model,k):
  rfe = RFE(model, n_features_to_select=k, step=1)
  fit = rfe.fit(X, y)
  X_new = fit.support_
  print("Num Features: %s" % (fit.n_features_))
  print("Selected Features: %s" % (fit.support_))
  print("Feature Ranking: %s" % (fit.ranking_))

  return X_new

# Establecer Estimador
model = LogisticRegression(max_iter=1000, solver = 'liblinear')
# Obtener columnas seleciconadas - (10 caracteristicas)
X_new = recursive_feature_selection(X, y, model, 10)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train,y_train)*100) + "%")
print("Score: ", regr.score(X_train, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test,y_test)*100) + "%")

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_train, y_pred)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_test, y_hat)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

TP=cm1[0,0]
FP=cm1[1,0]
FN=cm1[0,1]
TN=cm1[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""## K BEST
Selección de características de acuerdo con las k puntuaciones más altas.
Utiliza una función que toma dos matrices X e y, y devuelve un par de matrices (puntuaciones, valores de p) o una única matriz con puntuaciones.
"""

from sklearn.feature_selection import SelectKBest, f_regression

# Función de filtro de caracteristicas - stadis. scores
def select_kbest(X,y,score_f,k):
    sel_kb = SelectKBest(score_func=score_f, k=k)
    sel_kb.fit(X,y)
    new_cols = sel_kb.get_support()
    print("Scores:\n", sel_kb.scores_, "\nP-values:\n", sel_kb.pvalues_)
    return new_cols

X= df2_dummys
y = df_datafinal.iloc[:,-1]

# LabelEncoder
#from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

#print(y[0:5])

# Obtener columnas seleciconadas -
X_new = select_kbest(X, y, f_regression,10)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')



"""##**Lasso**
SelectFromModel Meta-transformador para seleccionar características basadas en pesos de importancia.
"""

X = df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler

# Estandarizar los datos
standard_scaler = StandardScaler()
X_std = standard_scaler.fit_transform(X)

# Selector de variables con Lasso
sel_ = SelectFromModel(Lasso(alpha=0.05), max_features=4)
sel_.fit(X_std, y)
print(sel_.estimator_.coef_)
#Obtener variables seleccionadas
X_new = sel_.get_support()

df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)
# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""## **Sequential Feature Selector**
Este selector secuencial de caracteristicas agrega (selección hacia adelante) o elimina (selección hacia atrás) caracteristicas para formar un subconjunto de caracteristicas de manera codiciosa.

En cada etapa, este estimador elige la mejor característica para agregar o eliminar en función de la puntuación de validación cruzada de un estimador.
"""

X= df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.feature_selection import SequentialFeatureSelector

# Selector secuencias utilizando regresión logísticas
sfs = SequentialFeatureSelector(LinearRegression(),
                                n_features_to_select=5,
                                direction= "forward",
                                scoring='r2')
# Obtener variable seleccionadas
sfs = sfs.fit(X, y)
X_new = sfs.support_
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')



"""##Selección: 10 variables

###RFE
El objetivo de la eliminación recursiva de características (RFE) es seleccionar características considerando recursivamente conjuntos de características cada vez más pequeños.
"""

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

from sklearn.feature_selection import RFE

# Función recursiva de selección de características
def recursive_feature_selection(X,y,model,k):
  rfe = RFE(model, n_features_to_select=k, step=1)
  fit = rfe.fit(X, y)
  X_new = fit.support_
  print("Num Features: %s" % (fit.n_features_))
  print("Selected Features: %s" % (fit.support_))
  print("Feature Ranking: %s" % (fit.ranking_))

  return X_new

# Establecer Estimador
model = LogisticRegression(max_iter=1000, solver = 'liblinear')
# Obtener columnas seleciconadas - (10 caracteristicas)
X_new = recursive_feature_selection(X, y, model, 10)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train,y_train)*100) + "%")
print("Score: ", regr.score(X_train, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test,y_test)*100) + "%")

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_train, y_pred)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_test, y_hat)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###Variance Threshold
Elimina todas las características cuya varianza no alcanza algún umbral.
De forma predeterminada, elimina todas las características de varianza cero, es decir, las características que tienen el mismo valor en todas las muestras.
"""

X = df2_dummys

#Variance Threshold
from sklearn.feature_selection import VarianceThreshold

#Función de filtro de caracteristicas
def variance_threshold(x,th):
    var_thres=VarianceThreshold(threshold=th)
    var_thres.fit(x)
    new_cols = var_thres.get_support()
    return new_cols

# Obtener columnas seleccionadas
X_new = variance_threshold(X, 0.5)
# Nuevo dataframe
df_new = df2_dummys.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###K BEST
Selección de características de acuerdo con las k puntuaciones más altas.
Utiliza una función que toma dos matrices X e y, y devuelve un par de matrices (puntuaciones, valores de p) o una única matriz con puntuaciones.texto en negrita
"""

from sklearn.feature_selection import SelectKBest, f_regression

# Función de filtro de caracteristicas - stadis. scores
def select_kbest(X,y,score_f,k):
    sel_kb = SelectKBest(score_func=score_f, k=k)
    sel_kb.fit(X,y)
    new_cols = sel_kb.get_support()
    print("Scores:\n", sel_kb.scores_, "\nP-values:\n", sel_kb.pvalues_)
    return new_cols

X= df2_dummys
y = df_datafinal.iloc[:,-1]

# LabelEncoder
#from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

#print(y[0:5])

# Obtener columnas seleccionadas -
X_new = select_kbest(X, y, f_regression,10)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""### Sequential Feature Selector
Este selector secuencial de caracteristicas agrega (selección hacia adelante) o elimina (selección hacia atrás) caracteristicas para formar un subconjunto de caracteristicas de manera codiciosa.

En cada etapa, este estimador elige la mejor característica para agregar o eliminar en función de la puntuación de validación cruzada de un estimador.
"""

X= df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.feature_selection import SequentialFeatureSelector

# Selector secuencias utilizando regresión logísticas
sfs = SequentialFeatureSelector(LinearRegression(),
                                n_features_to_select=5,
                                direction= "forward",
                                scoring='r2')
# Obtener variable seleccionadas
sfs = sfs.fit(X, y)
X_new = sfs.support_
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###Lasso
SelectFromModel Meta-transformador para seleccionar características basadas en pesos de importancia.
"""

X = df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler

# Estandarizar los datos
standard_scaler = StandardScaler()
X_std = standard_scaler.fit_transform(X)

# Selector de variables con Lasso
sel_ = SelectFromModel(Lasso(alpha=0.05), max_features=4)
sel_.fit(X_std, y)
print(sel_.estimator_.coef_)
#Obtener variables seleccionadas
X_new = sel_.get_support()

df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)
# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""##Selección: 20 variables

###SELECTKABEST
"""

# SELECTKABEST
from sklearn.feature_selection import SelectKBest, f_regression

# Función de filtro de caracteristicas - stadis. scores
def select_kbest(X,y,score_f,k):
    sel_kb = SelectKBest(score_func=score_f, k=k)
    sel_kb.fit(X,y)
    new_cols = sel_kb.get_support()
    print("Scores:\n", sel_kb.scores_, "\nP-values:\n", sel_kb.pvalues_)
    return new_cols

X= df2_dummys
y = df_datafinal.iloc[:,-1]
# LabelEncoder
#from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Obtener columnas seleciconadas - (20 caracteristicas)
X_new = select_kbest(X, y, f_regression,20)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*10) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###SequentialFeatureSelector"""

X= df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.feature_selection import SequentialFeatureSelector

# Selector secuencias utilizando regresión logísticas
sfs = SequentialFeatureSelector(LinearRegression(),
                                n_features_to_select=20,
                                direction= "forward",
                                scoring='r2')
# Obtener variable seleccionadas
sfs = sfs.fit(X, y)
X_new = sfs.support_
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100)+'%')
print("Score",regr.score(X_train_std,y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###RFE"""

#RFE
from sklearn.feature_selection import RFE

# Función recursiva de selección de características
def recursive_feature_selection(X,y,model,k):
  rfe = RFE(model, n_features_to_select=k, step=1)
  fit = rfe.fit(X, y)
  X_new = fit.support_
  print("Num Features: %s" % (fit.n_features_))
  print("Selected Features: %s" % (fit.support_))
  print("Feature Ranking: %s" % (fit.ranking_))

# Establecer Estimador
model = LogisticRegression(max_iter=1000, solver='liblinear')

# Obtener columnas seleccionadas - (20 características)
x_new= recursive_feature_selection(X, y, model, 20)

# Convertir X_new en una lista
# selected_columns = x_new.tolist()   ########### REVISAR QUE PASA
# Nuevo conjunto de datos
#df_new = X.iloc[:, selected_columns]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train,y_train)*100) + "%")
print("Score: ", regr.score(X_train, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test,y_test)*100) + "%")

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_test, y_hat)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')



"""##Selección: 30 variables

###SELECTKABEST
"""

# SELECTKABEST
from sklearn.feature_selection import SelectKBest, f_regression

# Función de filtro de caracteristicas - stadis. scores
def select_kbest(X,y,score_f,k):
    sel_kb = SelectKBest(score_func=score_f, k=k)
    sel_kb.fit(X,y)
    new_cols = sel_kb.get_support()
    print("Scores:\n", sel_kb.scores_, "\nP-values:\n", sel_kb.pvalues_)
    return new_cols

X= df2_dummys
y = df_datafinal.iloc[:,-1]
# LabelEncoder
#from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Obtener columnas seleciconadas - (3 caracteristicas)
X_new = select_kbest(X, y, f_regression,30)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*10) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###RFE"""

#RFE
from sklearn.feature_selection import RFE

# Función recursiva de selección de características
def recursive_feature_selection(X,y,model,k):
  rfe = RFE(model, n_features_to_select=k, step=1)
  fit = rfe.fit(X, y)
  X_new = fit.support_
  print("Num Features: %s" % (fit.n_features_))
  print("Selected Features: %s" % (fit.support_))
  print("Feature Ranking: %s" % (fit.ranking_))

  return X_new

# Establecer Estimador
model = LogisticRegression(max_iter=1000, solver = 'liblinear')
# Obtener columnas seleciconadas - (30 caracteristicas)
X_new = recursive_feature_selection(X, y, model, 30)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

import numpy as np
np.seterr(under='ignore')
# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train,y_train)*100) + "%")
print("Score: ", regr.score(X_train, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test,y_test)*100) + "%")

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_test, y_hat)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###SequentialFeatureSelector"""

X= df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.feature_selection import SequentialFeatureSelector

# Selector secuencias utilizando regresión logísticas
sfs = SequentialFeatureSelector(LinearRegression(),
                                n_features_to_select=30,
                                direction= "forward",
                                scoring='r2')
# Obtener variable seleccionadas
sfs = sfs.fit(X, y)
X_new = sfs.support_
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""## Seleccion: 39 variables

###RFE
"""

from sklearn.feature_selection import RFE

# Función recursiva de selección de características
def recursive_feature_selection(X,y,model,k):
  rfe = RFE(model, n_features_to_select=k, step=1)
  fit = rfe.fit(X, y)
  X_new = fit.support_
  print("Num Features: %s" % (fit.n_features_))
  print("Selected Features: %s" % (fit.support_))
  print("Feature Ranking: %s" % (fit.ranking_))

  return X_new

# Establecer Estimador
model = LogisticRegression(max_iter=1000, solver = 'liblinear')
# Obtener columnas seleciconadas - (40 caracteristicas)
X_new = recursive_feature_selection(X, y, model, 40)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)

import numpy as np
np.seterr(under='ignore')

# Calibra el modelo
regr.fit(X_train, y_train)

#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train,y_train)*100) + "%")
print("Score: ", regr.score(X_train, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test,y_test)*100) + "%")

#validar modelo
# Exactitud del modelo
print(f"Accuracy of the classifier is: {accuracy_score(y_test, y_hat)}")

# Matriz de confusion
cm1= confusion_matrix(y_test, y_hat)
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1, display_labels = [False, True])
cm1_display.plot()
plt.show()

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

X= df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

"""SelectKBest"""

from sklearn.feature_selection import SelectKBest, f_regression

# Función de filtro de caracteristicas - stadis. scores
def select_kbest(X,y,score_f,k):
    sel_kb = SelectKBest(score_func=score_f, k=k)
    sel_kb.fit(X,y)
    new_cols = sel_kb.get_support()
    print("Scores:\n", sel_kb.scores_, "\nP-values:\n", sel_kb.pvalues_)
    return new_cols

X= df2_dummys
y = df_datafinal.iloc[:,-1]

# LabelEncoder
#from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Obtener columnas seleciconadas
X_new = select_kbest(X, y, f_regression,40)
# Nuevo conjunto de datos
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:, -1].values # target

# LabelEncoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*10) + "%")
print("Score: ", regr.score(X_train_std, y_pred))


#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""###SequentialFeatureSelector"""

num_filas, num_columnas = df_new.shape

print(f'El conjunto de datos tiene {num_filas} filas y {num_columnas} columnas.')

from sklearn.feature_selection import SequentialFeatureSelector

# Selector secuencias utilizando regresión logísticas
sfs = SequentialFeatureSelector(LinearRegression(),
                                n_features_to_select=39,
                                direction= "forward",
                                scoring='r2')
# Obtener variable seleccionadas
sfs = sfs.fit(X, y)
X_new = sfs.support_
df_new = X.iloc[:,X_new]
df_new.head()

X = df_new
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

#VALIDAR MODELO
#validar modelo
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Precision: {TP/(TP+FP)}')
print(f'Recuperacion: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""# **f. Selección y aplicación de algoritmos/técnicas de modelado**

Aplicar al menos tres algoritmos de aprendizaje supervisado vistos en clase, como Regresión Logística, Árboles de Decisión, Random Forest, Support Vector Machine, y otros. Entrenar y evaluar estos modelos utilizando métricas adecuadas, como precisión, sensibilidad, especificidad, F1-score, etc.

##**Regresión Logistica normal**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
#Crea el modelo
regr = LogisticRegression()
#Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

"""En esta matriz:

709 representan los verdaderos positivos (True Positives, TP). Son las instancias que fueron clasificadas correctamente como positivas por el modelo.

32 representan los falsos negativos (False Negatives, FN). Son las instancias que eran positivas pero fueron clasificadas incorrectamente como negativas por el modelo.

101 representan los falsos positivos (False Positives, FP). Son las instancias que eran negativas pero fueron clasificadas incorrectamente como positivas por el modelo.

40 representa los verdaderos negativos (True Negatives, TN). Son las instancias que fueron clasificadas correctamente como negativas por el modelo.
"""

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]

print(f'Accuracy: {(TP+TN)/(TP+TN+FP+FN)}')
print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""*   El modelo tiene una exactitud aproximada del 84.92%. Esto significa que alrededor del 84.92% de todas las predicciones realizadas por el modelo son correctas. Sin embargo, la exactitud por sí sola puede no ser suficiente para evaluar completamente el rendimiento del modelo, especialmente si el conjunto de datos está desequilibrado.
*   El modelo tiene un alto recall (Sensibilidad o Tasa de Verdaderos Positivos) de aproximadamente 95.6%. Esto indica que el modelo es eficaz para capturar la mayoría de las instancias positivas en el conjunto de datos. En otras palabras, el modelo tiende a minimizar los falsos negativos, lo que es importante si los falsos negativos son costosos o críticos en la aplicación.
*   La precisión del modelo es aproximadamente 87.65%. Esto significa que, de todas las instancias que el modelo clasifica como positivos, alrededor del 87.65% son verdaderamente positivos. El modelo tiende a minimizar los falsos positivos.
*   El F1-Score es una métrica que combina precisión y recuperación en un solo valor. Con un F1-Score de aproximadamente 91.5%, el modelo muestra un buen equilibrio entre la capacidad de clasificar correctamente las instancias positivas y negativas.

En general, el modelo parece ser bastante efectivo en la tarea de clasificación. Tiene una alta sensibilidad, lo que sugiere que es bueno para detectar casos positivos. Sin embargo, la precisión no es tan alta como el recall, lo que significa que puede haber un número significativo de falsos positivos.

## **Regresión Logistica Balanceada**
"""

#vamos a relizar un modelo balanceado
from sklearn.linear_model import LogisticRegression

# Crea el modelo
regr = LogisticRegression(class_weight="balanced", random_state=42, max_iter=1000)
# Calibra el modelo
regr.fit(X_train_std, y_train)
#Realice predicciones sobre x_train_std
y_pred = regr.predict(X_train_std)
# Imprime los coeficientes
print("Coeficientes: ", regr.coef_)

# Imprime el intercepto
print("\nIntercepto: ", regr.intercept_)
#Exactitud de modelo
print("Accuracy (Train): "+ str(regr.score(X_train_std,y_train)*100) + "%")
print("Score: ", regr.score(X_train_std, y_pred))

#Predicciones sobre el conjunto de test
y_hat = regr.predict(X_test_std)
#Exactitud de modelo
print("Accuracy (Test): "+ str(regr.score(X_test_std,y_test)*100) + "%")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_hat)
disp = ConfusionMatrixDisplay(confusion_matrix = cm)
disp.plot(cmap='CMRmap_r')
plt.show()
print(cm)

"""Verdaderos Positivos (TP) = 544
Falsos Negativos (FN) = 197
Falsos Positivos (FP) = 37
Verdaderos Negativos (TN) = 104
"""

TP=cm[0,0]
FP=cm[1,0]
FN=cm[0,1]
TN=cm[1,1]
print(f'Accuracy: {(TP+TN)/(TP+TN+FP+FN)}')
print(f'Precisión: {TP/(TP+FP)}')
print(f'Recuperación: {TP/(TP+FN)}')
precision=TP/(TP+FP)
recall=TP/(TP+FN)
print(f'F1-score: {(2*precision*recall)/(precision+recall)}')
print(f'Especificidad: {TN/(FP+TN)}')

"""Ahora, podemos comparar estos resultados con los del modelo anterior:

Modelo Original (desbalanceado):


*   Exactitud (Accuracy): Aproximadamente 0.8492
*   Precisión (Precision): Aproximadamente 0.8765
*   F1-Score: Aproximadamente 0.915
*   Recall (Sensibilidad): Aproximadamente 0.956

Modelo Balanceado (nuevo):

*   Exactitud (Accuracy): Aproximadamente  0.7346
*   Precisión (Precision): Aproximadamente 0.9364
*   F1-Score: Aproximadamente 0.82
*   Recall (Sensibilidad): Aproximadamente 0.7331

Comparando ambos modelos:


*  El modelo original tiene una mayor exactitud y recall que el modelo balanceado, lo que significa que es mejor para detectar casos positivos, pero tiene una precisión ligeramente menor.
*   El modelo balanceado tiene una mayor precisión que el modelo original.
*  El F1-Score es comparable entre ambos modelos, pero el modelo original tiene un F1-Score ligeramente superior.

## **Kfold Cross Val**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import ShuffleSplit

X = df2_dummys
y = df_datafinal.iloc[:,-1]
le = LabelEncoder()
y = le.fit_transform(y)

kfld = KFold(n_splits=10,random_state=6,shuffle=True) #se puede jugar con n_splits (k), random(semilla)

modelo = LogisticRegression(solver='liblinear')

res = cross_val_score(modelo,X,y, cv=kfld)

res.mean()*100

loo = LeaveOneOut()

modelo = LogisticRegression(solver='liblinear')

res = cross_val_score(modelo,X,y, cv=loo)

res.mean()*100

# Separación en conjuntos de entrenamiento y validación con 80% de muestras para entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Imprimir Tamaño de dataset
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de validación:", X_test.shape)

#Nombre de caracteristicas númericas
numeric_columns=list(X.select_dtypes('float64').columns)

#Estandarización de variables númericas
pipeline=ColumnTransformer([("std_num" , StandardScaler(), numeric_columns)], remainder='passthrough')

X_train_std = pipeline.fit_transform(X_train)
X_test_std = pipeline.transform(X_test)

# Otra alternativa utilizando LogisticRegressionCV
from sklearn.linear_model import LogisticRegressionCV
from sklearn.metrics import f1_score

# Definición de modelo y ajuste a todos los datos
clf = LogisticRegressionCV(cv=5, random_state=0, scoring='f1', max_iter=1000, solver = 'liblinear').fit(X, y)

print("Score: ", clf.score(X_test, y_test))
print("F1-score: ", f1_score(y_test, y_hat))

"""**Conclusión:**
1. El F1-score del modelo es de 0.46 Por lo que seguimos con problemas para predecir de manera correcta .
2. Como pudimos observar para este problema  la regresion  logistica no es un metodo muy acertado para predecir, ya que los modelos evaluados anteriormente no tienen metricas tan buenas por lo que analizaremos con otros metodos mas avanzados para ver si mejora las predicciones.

##**Árboles de decisión**
"""

from scipy.stats import randint

treedf = tree.DecisionTreeClassifier(
          criterion = 'gini',
          random_state=0)
treedf.fit(X_train_std, y_train)

# Métricas de desempeño
print ("Train - Accuracy :", metrics.accuracy_score(y_train, treedf.predict(X_train_std)))
print ("Train - classification report:\n", metrics.classification_report(y_train, treedf.predict(X_train_std)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, treedf.predict(X_test_std)))
print ("Test - classification report :", metrics.classification_report(y_test, treedf.predict(X_test_std)))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Matriz de confusion
cm1= confusion_matrix(y_test, treedf.predict(X_test_std))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

tree.plot_tree(treedf) #Observemos graficamente el arbol

"""###**Ajustamos los parámetros**"""

treedf.get_params()

param_grid = {
    "max_depth": [3,5,10,15,20,None],
    "min_samples_split": [3, 5,7,10],
    "min_samples_leaf": [2,3,5]
}

from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV

grid_cv = GridSearchCV(treedf, param_grid, scoring="roc_auc", n_jobs=-1, cv=5).fit(X_train_std, y_train)

print("Param for GS", grid_cv.best_params_)
print("CV score for GS", grid_cv.best_score_)

# compute ccp_alpha values
path = treedf.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

# train DT classifier for each ccp_alpha value
clfs = []
for ccp_alpha in ccp_alphas:
    clf = tree.DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)

# Plot train and test score for each of the above trained model
clfs = clfs[:-1]
ccp_alphas = ccp_alphas[:-1]

train_scores = [roc_auc_score(y_train, td2.predict(X_train)) for td2 in clfs]
test_scores = [roc_auc_score(y_test, td2.predict(X_test)) for td2 in clfs]

fig, ax = plt.subplots()
ax.set_xlabel("alpha")
ax.set_ylabel("accuracy")
ax.set_title("AUC-ROC score vs alpha")
ax.plot(ccp_alphas, train_scores, marker='o', label="train")
ax.plot(ccp_alphas, test_scores, marker='o', label="test")
ax.legend()
plt.show()

treedf = tree.DecisionTreeClassifier(
          criterion = 'gini',
          max_depth= 15, min_samples_leaf= 2, min_samples_split= 3,
          random_state=0)
treedf.fit(X_train_std, y_train)

# Métricas de desempeño
print ("Train - Accuracy :", metrics.accuracy_score(y_train, treedf.predict(X_train_std)))
print ("Train - classification report:\n", metrics.classification_report(y_train, treedf.predict(X_train_std)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, treedf.predict(X_test_std)))
print ("Test - classification report :", metrics.classification_report(y_test, treedf.predict(X_test_std)))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Matriz de confusion
cm1= confusion_matrix(y_test, treedf.predict(X_test_std))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

kfold = KFold(n_splits=10, random_state=7, shuffle=True)
score='accuracy'
crosstrain = cross_val_score(treedf, X_train, y_train, cv=kfold, scoring=score,error_score='raise')
crosstest = cross_val_score(treedf, X_test, y_test, cv=kfold, scoring=score,error_score='raise')
print('Accuracy for train= ',crosstrain.mean()*100)
print('Accuracy for test= ',crosstest.mean()*100)

"""**Antes del Ajuste de Parámetros:**

En el conjunto de entrenamiento:

Accuracy: 1.0
Precision, Recall y F1-score para la clase 0 son todos 1.0, lo que indica un ajuste perfecto para esa clase.
Precision, Recall y F1-score para la clase 1 son también 1.0, lo que indica un ajuste perfecto para esa clase.

En el conjunto de prueba:
Accuracy: 0.9705
Aunque el modelo es altamente preciso, muestra un pequeño desequilibrio en la clase 1 con una precisión más baja y un recall más alto en comparación con la clase 0.

**Después del Ajuste de Parámetros:**

En el conjunto de entrenamiento:

Accuracy: 0.9926
Aunque la precisión es alta, el modelo ahora muestra un poco de desequilibrio en la clase 1, con una precisión ligeramente menor y un recall ligeramente menor en comparación con la clase 0.

En el conjunto de prueba:

Accuracy: 0.9433
El modelo sigue siendo preciso, pero ha experimentado una disminución en la precisión, el recall y el F1-score para ambas clases en comparación con el modelo sin ajustar.


El modelo sin ajustar los parámetros tiene una precisión casi perfecta en el conjunto de entrenamiento, lo que sugiere un posible sobreajuste a los datos de entrenamiento. Sin embargo, en el conjunto de prueba, aunque la precisión es alta, el modelo muestra un desequilibrio en la clase 1.
Después de ajustar los parámetros, el modelo generaliza mejor en el conjunto de prueba, lo que se refleja en una disminución del sobreajuste, pero aún muestra un desequilibrio en las métricas de rendimiento para la clase 1.

##**Random forest**
"""

from sklearn.ensemble import RandomForestClassifier
#Definición del modelo
ranfor = RandomForestClassifier(random_state = 123, n_estimators=100)
ranfor.fit(X_train, y_train)

# Métricas de desempeño
print ("Train - Accuracy :", metrics.accuracy_score(y_train, ranfor.predict(X_train)))
print ("Train - classification report:\n", metrics.classification_report(y_train, ranfor.predict(X_train)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, ranfor.predict(X_test)))
print ("Test - classification report :", metrics.classification_report(y_test, ranfor.predict(X_test)))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Matriz de confusion
cm1= confusion_matrix(y_test, ranfor.predict(X_test))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

"""Este modelo muestra un rendimiento sobresaliente, con una precisión global del 99%, lo que implica que clasifica la gran mayoría de los casos de manera correcta.
Además, el modelo exhibe una alta precisión, recall y F1-score para ambas clases, lo que sugiere que es capaz de clasificar con precisión todas las observaciones.

Sin embargo, es importante destacar que estas métricas podrían ser indicativas de un posible sobreajuste, lo que significa que el modelo pudo haber aprendido los datos de manera tan detallada que se ajustó excesivamente a ellos. Por lo tanto, planeamos realizar ajustes en los parámetros para abordar este problema.
Además, es relevante mencionar que en la matriz de confusión no se observan falsos negativos, y los falsos positivos son muy escasos.
"""

param_grid = {
    "max_depth": [5,15,20,30],
    "min_samples_split": [3,5,10],
    "min_samples_leaf": [2,3,5,10,],
    'n_estimators': [100,115,200,500]
}

from sklearn.ensemble import RandomForestClassifier
#Definición del modelo
ranfor = RandomForestClassifier(random_state = 42)

grid_search = GridSearchCV(ranfor, param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_result = grid_search.fit(X_train, y_train)

print('Best Params: ', grid_result.best_params_)
print('Best Score: ', grid_result.best_score_)

ranfor = RandomForestClassifier(
            n_estimators = 115,
            criterion    = 'gini',
            max_depth    = 20,
            min_samples_leaf = 2,
            min_samples_split = 3,
            random_state = 42
         )
ranfor.fit(X_train, y_train)

# Métricas de desempeño
print ("Train - Accuracy :", metrics.accuracy_score(y_train, ranfor.predict(X_train)))
print ("Train - classification report:\n", metrics.classification_report(y_train, ranfor.predict(X_train)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, ranfor.predict(X_test)))
print ("Test - classification report :", metrics.classification_report(y_test, ranfor.predict(X_test)))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Matriz de confusion
cm1= confusion_matrix(y_test, ranfor.predict(X_test))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

"""El modelo presenta una precisión global del 96%, lo que indica que clasifica la gran mayoría de los casos de manera correcta.
No obstante, se observa que la precisión para la clase 1 es del 100%, pero el recall y el F1-score son ligeramente más bajos,
lo que sugiere que el modelo podría tener dificultades para identificar adecuadamente los casos de la clase 1.

En la matriz de confusión, notamos un aumento en los falsos positivos, aunque los falsos negativos siguen siendo cero.
En general, se podría considerar que este es un buen modelo, pero sigue siendo importante tener en cuenta la posibilidad de sobreajuste,
dado que las métricas podrían no reflejar completamente la capacidad del modelo en datos nuevos o desconocidos.

## Gradient Boosting Classifier
"""

from sklearn.ensemble import GradientBoostingClassifier

# Entrenamiento del modelo

gboos = GradientBoostingClassifier(

            random_state = 123
         )
gboos.fit(X_train, y_train)

# Métricas de desempeño
# ==============================================================================
print ("Train - Accuracy :", metrics.accuracy_score(y_train, gboos.predict(X_train)))
print ("Train - classification report:\n", metrics.classification_report(y_train, gboos.predict(X_train)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, gboos.predict(X_test)))
print ("Test - classification report :", metrics.classification_report(y_test, gboos.predict(X_test)))

# Matriz de confusion
cm1= confusion_matrix(y_test, gboos.predict(X_test))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

"""El modelo de Gradient Boosting Classifier demostró ser una técnica sólida en la tarea de predecir el abandono de empleados en nuestra empresa. Aunque su precisión y recuperación no alcanzan los niveles sobresalientes del Random Forest, el Gradient Boosting Classifier ofrece un equilibrio razonable entre precisión y recuperación en ambos conjuntos de datos, lo que lo hace adecuado para esta tarea. Su capacidad para identificar empleados en riesgo de abandonar la empresa y su rendimiento en el conjunto de prueba respaldan su utilidad en la toma de decisiones estratégicas relacionadas con la retención de empleados. Sin embargo, es importante destacar que aún existen oportunidades de mejora y ajustes en hiperparámetros que podrían optimizar aún más su desempeño en futuras iteraciones del modelo

## Support Vector Machine
"""

from sklearn.svm import SVC
svm_model = SVC(
                C = 1.5,
                kernel = 'linear',
                class_weight = 'balanced',
                random_state=123)
svm_model.fit(X_train, y_train)

# Métricas de desempeño
# ==============================================================================
print ("Train - Accuracy :", metrics.accuracy_score(y_train, svm_model.predict(X_train)))
print ("Train - classification report:\n", metrics.classification_report(y_train, svm_model.predict(X_train)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, svm_model.predict(X_test)))
print ("Test - classification report :", metrics.classification_report(y_test, svm_model.predict(X_test)))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Matriz de confusion
cm1= confusion_matrix(y_test, svm_model.predict(X_test))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

"""el SVM logra una precisión de alrededor del 45% en el conjunto de prueba, lo que indica que es capaz de clasificar correctamente una proporción significativa de las muestras. Sin embargo, su recuperación (recall) es aproximadamente del 79%, lo que sugiere que el modelo tiende a identificar correctamente la mayoría de las muestras positivas. Estos resultados revelan que el SVM puede ser útil en la identificación de empleados que están en riesgo de abandonar la empresa, aunque su precisión general es limitada.

# **g. Comparación y selección de técnicas**

Comparar el rendimiento de los modelos y seleccionar el que mejor se ajuste al problema.

se llevó a cabo un exhaustivo análisis de varios modelos de aprendizaje automático con el objetivo de determinar cuál de ellos es más adecuado para abordar el desafío de predecir el abandono de empleados en nuestra organización. Se evaluaron seis modelos diferentes, cada uno con sus propias características y capacidades. El análisis se centró en métricas fundamentales como precisión, recuperación y F1-score, así como en la capacidad de los modelos para realizar predicciones precisas tanto en el conjunto de entrenamiento como en el conjunto de prueba. A continuación, se presenta una descripción detallada de los resultados.

Random Forest:
•	Train - Accuracy: 0.9972
•	Test - Accuracy: 0.9660

Gradient Boosting Classifier:
•	Train - Accuracy: 0.9306
•	Test - Accuracy: 0.9082

Árboles de Decisión:
•	Accuracy (Train): 0.9926
•	Accuracy (Test): 0.9433

Regresión Logística (Balanceada):
•	Accuracy: 0.7279
•	F1-score: 0.8187
•	Precisión: 0.9297
•	Recuperación: 0.7314

Regresión Logística (No balanceada):
•	Accuracy: 0.8492
•	F1-score: 0.9142
•	Precisión: 0.8753
•	Recuperación: 0.9568

Support Vector Machine (SVM):
•	Train - Accuracy: 0.4595
•	Test - Accuracy: 0.4354


Con base a los resultados, el modelo Random Forest destaca como la mejor técnica para predecir el abandono de empleados en este caso.
"""



"""# **h. Afinamiento de hiperparámetros**

Optimizar los hiperparámetros de los modelos seleccionados para mejorar su rendimiento. Esto podría realizarse mediante técnicas como Grid Search o Random Search.
"""

# Definición de cuadricula de hiperparametros
parameters = {'learning_rate': [0.05,0.1,0.3],
              'max_depth': [4,6,8,10],
              'n_estimators': [100,150,200,500]}

from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV

XGBmodel = XGBClassifier(random_state=42)
rand_s = RandomizedSearchCV(estimator=XGBmodel, param_distributions=parameters, n_iter=10, scoring='r2', cv=5, verbose=True)

rand_s.fit(X_train, y_train)

print('Best Params: ', rand_s.best_params_)
print('Best Score: ', rand_s.best_score_)

gboos = GradientBoostingClassifier(
            n_estimators = 500,
            max_depth= 6,
            random_state = 123,  learning_rate= 0.3
         )
gboos.fit(X_train, y_train)

# Métricas de desempeño
# ==============================================================================
print ("Train - Accuracy :", metrics.accuracy_score(y_train, gboos.predict(X_train)))
print ("Train - classification report:\n", metrics.classification_report(y_train, gboos.predict(X_train)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, gboos.predict(X_test)))
print ("Test - classification report :", metrics.classification_report(y_test, gboos.predict(X_test)))

# Matriz de confusion
cm1= confusion_matrix(y_test, gboos.predict(X_test))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

"""**Conclusión:**
se observa una mejora significativa en el rendimiento de los modelos. El GradientBoostingClassifier logra un rendimiento excepcional después del ajuste de parámetros, con una precisión del 100% tanto en el conjunto de entrenamiento como en el conjunto de prueba. Esto indica que el modelo es capaz de clasificar perfectamente las muestras en ambos conjuntos y que ha aprendido con gran precisión las relaciones en los datos.

##Support Vector Machine
"""

from sklearn.svm import SVC
svm_model = SVC(
                C = 1.5,
                kernel = 'linear',
                class_weight = 'balanced',
                random_state=123)
svm_model.fit(X_train, y_train)

# Métricas de desempeño
# ==============================================================================
print ("Train - Accuracy :", metrics.accuracy_score(y_train, svm_model.predict(X_train)))
print ("Train - classification report:\n", metrics.classification_report(y_train, svm_model.predict(X_train)))
print ("Test - Accuracy :", metrics.accuracy_score(y_test, svm_model.predict(X_test)))
print ("Test - classification report :", metrics.classification_report(y_test, svm_model.predict(X_test)))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Matriz de confusion
cm1= confusion_matrix(y_test, svm_model.predict(X_test))
# Visualización de la matriz de confusion
cm1_display = ConfusionMatrixDisplay(confusion_matrix = cm1)
cm1_display.plot()
plt.show()

"""**Conclusión**
 el modelo Support Vector Machine (SVM) también muestra una mejora en su rendimiento después del afinamiento de parámetros, aunque sigue siendo inferior en términos de precisión en comparación con el GradientBoostingClassifier. El SVM ahora logra una precisión del 46% en el conjunto de entrenamiento y del 44% en el conjunto de prueba. Si bien esta mejora es significativa, el SVM aún muestra una precisión relativamente baja en comparación con otros modelos.

# **i. Evaluación y análisis del mejor modelo**

Evaluar el mejor modelo en términos de métricas de rendimiento y analizar sus características más importantes para entender qué variables influyen más en la retención de empleados.

# **j. Conclusiones finales y recomendaciones**

Conclusiones
Este proyecto proporciona una clara y sólida evidencia de que la retención de empleados es un desafío crítico para la agencia de marketing Sterling Cooper Advertising. A lo largo de este trabajo, se ha demostrado que la retención de empleados puede ser abordada y mejorada mediante un análisis de datos inteligente y el uso de técnicas avanzadas de aprendizaje automático.
Después de un riguroso proceso de evaluación y ajuste de hiperparámetros, el modelo GradientBoostingClassifier se destacó como el más preciso y efectivo para predecir la retención de empleados. Con una precisión del 99.32% en el conjunto de prueba, este modelo superó ampliamente a las alternativas.
El análisis de importancia de características identificó las variables más influyentes en la retención de empleados. Estas incluyen la antigüedad en la empresa, la edad, la satisfacción laboral, el trabajo extra y el total de años trabajados. Estas variables ofrecen un enfoque claro para la mejora de la retención.
El proceso de afinamiento de hiperparámetros desempeñó un papel crucial en la mejora del rendimiento del mejor modelo. Los parámetros ajustados permitieron que el modelo alcance su máximo potencial y capture relaciones más precisas en los datos.
A partir de los resultados obtenidos, se recomienda a Sterling Cooper Advertising tomar las siguientes medidas:
Dado que la satisfacción laboral es una variable crucial en la retención de empleados, la empresa debería esforzarse por mejorar la experiencia de los empleados y garantizar un entorno de trabajo positivo. Ofrecer oportunidades de desarrollo profesional y crecimiento en la empresa puede incentivar a los empleados a quedarse a largo plazo.
El tiempo que los empleados pasan en la empresa es un factor importante. Se deben implementar estrategias para mantener a los empleados comprometidos y satisfechos a lo largo del tiempo.
V. Recomendaciones Futuras:
La retención de empleados es un desafío constante. La empresa debe continuar monitoreando y analizando datos para adaptar sus estrategias a medida que cambian las condiciones internas y externas.
Implementar modelos de predicción en tiempo real puede ayudar a identificar a los empleados en riesgo de renunciar y tomar medidas preventivas de manera proactiva.
Realizar encuestas periódicas de satisfacción y retroalimentación de empleados puede proporcionar información valiosa sobre las necesidades y preocupaciones de los empleados.
Consideramos que este enfoque debería proporcionar a Sterling Cooper Advertising una comprensión sólida de su problema de rotación de empleados y una estrategia basada en datos para retener a su clave personal. Además, debería permitirles tomar medidas preventivas para evitar la pérdida de empleados valiosos en el futuro.
"""